# ğŸ§  Second Mind â€“ Agents-Based Research Assistant System

**Second Mind** is a modular, multi-agent AI system designed to automate key academic research tasks such as hypothesis generation, literature review, ranking, and refinement. Built with Python, the system simulates the collaboration of expert agents to streamline the research workflow from query to insight.

---

## ğŸ“˜ Project Description

This intelligent pipeline of agents enables researchers and students to:

- Automatically fetch the latest domain-specific research papers  
- Generate concise summaries using LLM-powered logic  
- Rank papers based on relevance and citation heuristics  
- Reflect on hypothesis validity with real-time feedback  
- Evolve and improve ideas iteratively  
- Monitor system performance with visual analytics

---

## ğŸš€ Key Features

- ğŸ§© **Modular Agent-Based Design** â€“ Each agent performs a distinct task in the research workflow  
- ğŸ” **Real-Time Web Search** â€“ Uses Google Custom Search for paper retrieval (e.g., arXiv, ResearchGate)  
- ğŸ§  **Topic-Aware Hypothesis Refinement** â€“ Evolve queries contextually based on current literature  
- ğŸ” **Query Caching** â€“ Reduces repeated processing via memory-based proximity checks  
- ğŸ“Š **Performance Monitoring** â€“ Track execution time, CPU & memory usage with real-time charts  
- ğŸ“ˆ **Visual Analytics** â€“ View detailed system behavior via Matplotlib graphs

---

## ğŸ¤– Core Agents

| Agent Name         | Responsibility                                                                 |
|--------------------|----------------------------------------------------------------------------------|
| **GenerationAgent**   | Fetches domain summaries and papers using Google Search API                    |
| **RankingAgent**      | Ranks papers by relevance score, citation strength, and semantic context       |
| **ReflectionAgent**   | Evaluates how well top papers support or conflict with the hypothesis          |
| **EvolutionAgent**    | Refines or rewrites hypotheses using learned context or keywords               |
| **ProximityAgent**    | Detects similar past queries to reuse memory and optimize performance          |
| **MetaReviewAgent**   | Logs and visualizes system metrics including execution time and memory usage   |

---

## ğŸ§  Technology Stack

- **Core Language**: Python 3.x  
- **Architecture**: Modular multi-agent system  
- **Key Libraries**:
  - `requests` â€“ Google Search API integration  
  - `dotenv` â€“ Secure environment variable management  
  - `psutil` â€“ Real-time resource monitoring  
  - `time`, `json`, `re`, `os` â€“ System control & I/O  
  - `matplotlib` â€“ Performance data visualization

---

## ğŸ“ˆ Performance Metrics Tracked

- Total query execution time  
- CPU and memory utilization per session  
- Cache hits vs misses  
- Number of processed queries  
- API call delays (if simulated or logged)

---

## ğŸ’¾ Data Handling

- Persistent memory stored in `memory.json`
- ProximityAgent uses this memory to reduce redundant computation and API calls
- Supports temporal and semantic matching for historical queries

---

## ğŸ“Š Visual Outputs

Matplotlib graphs generated after each query:

- **Bar Chart** â€“ Response time comparison  
- **Line Chart** â€“ CPU & memory usage over time  
- **Pie Chart** â€“ Cache hit vs miss ratio (optional)

---

## ğŸ—‚ï¸ Project Structure
AgentSystem/
â”‚
â”œâ”€â”€ agents/ # All AI agents
â”‚ â”œâ”€â”€ generation.py # Fetches domain content
â”‚ â”œâ”€â”€ ranking.py # Ranks results based on relevance
â”‚ â”œâ”€â”€ reflection.py # Evaluates query quality
â”‚ â”œâ”€â”€ evolution.py # Refines the query based on keywords
â”‚ â”œâ”€â”€ proximity.py # Memory lookup for similar past queries
â”‚ â””â”€â”€ meta_review.py # Performance evaluation agent
â”‚
â”œâ”€â”€ supervisor/
â”‚ â””â”€â”€ supervisor.py # Coordinates agent execution
â”‚
â”œâ”€â”€ storage/
â”‚ â””â”€â”€ memory.json # Query cache and memory log
â”‚
â”œâ”€â”€ main.py # Entry point for the system
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .env # API keys and configurations
â””â”€â”€ README.md # Project overview and usage

---

## ğŸ“Œ Future Improvements

- Integration with ArXiv API directly (to bypass scraping limitations)  
- GUI dashboard for real-time control of agent workflows  
- LLM fine-tuning on domain-specific research documents  
- Enhanced feedback loops between agents for adaptive intelligence

---

# SECOND MIND - Agents Based Research Assistant System

A modular multi-agent system designed to automate academic research tasks like hypothesis generation, literature search, ranking, reflection, and refinement using Python-based AI agents.

---

## ğŸ“˜ Project Description

This system simulates a collaborative pipeline of AI agents, each responsible for a specific task in the academic research process. It uses a modular architecture to:

- Fetch the latest research papers
- Generate summaries for a research domain
- Rank papers based on relevance
- Analyze and improve research hypotheses
- Track system performance

---

## ğŸš€ Key Features

- Modular agent-based design
- Real-time paper fetching from Google (arXiv, ResearchGate, etc.)
- Topic-aware hypothesis refinement
- Query caching via memory file
- Performance monitoring (CPU, memory, execution time)
- Visual analytics using matplotlib

---

## ğŸ¤– Core Agents

| Agent Name         | Functionality                                                                 |
|--------------------|--------------------------------------------------------------------------------|
| `GenerationAgent`  | Fetches domain summaries and recent research papers via Google Custom Search  |
| `RankingAgent`     | Ranks papers based on title relevance and assigns citation/reference scores   |
| `ReflectionAgent`  | Analyzes how well the hypothesis is supported by the top-ranked papers         |
| `EvolutionAgent`   | Refines hypotheses using topic-specific keywords or context from literature    |
| `ProximityAgent`   | Checks previous queries in memory to reuse past results                        |
| `MetaReviewAgent`  | Measures performance (time, CPU, memory) and provides feedback                 |

---

## ğŸ§  Technology Stack

### Backend / Core Logic

- Python 3.x
- Modular agent-based architecture

### Libraries & Tools

- `requests` â€“ For Google Custom Search API
- `dotenv` â€“ For managing API keys securely
- `psutil` â€“ For performance tracking (CPU/memory)
- `time` â€“ For query execution time tracking
- `json`, `os`, `re` â€“ For system operations and data parsing
- `matplotlib` â€“ For generating visual performance graphs

---

## ğŸ“ˆ Performance Metrics Tracked

- Query execution time
- CPU and memory usage
- Cache hits and misses
- Number of total queries
- API call delays (simulated or real)

---

## ğŸ’¾ Data Handling

- All past research queries and responses are stored in `memory.json`
- Used by `ProximityAgent` to avoid redundant processing

---

## ğŸ“Š Visual Outputs

Generated using `matplotlib` after processing each query:

- Response time bar chart
- CPU and memory usage line chart
- Cache hits vs misses pie chart (optional)

---

## ğŸ—‚ï¸ Project Structure
## ğŸ—‚ï¸ Project Structure

AgentSystem/
â”‚
â”œâ”€â”€ agents/                     # All intelligent agents  
â”‚   â”œâ”€â”€ generation.py           # Content generation agent  
â”‚   â”œâ”€â”€ ranking.py              # Ranking & filtering agent  
â”‚   â”œâ”€â”€ reflection.py           # Reflects on past responses  
â”‚   â”œâ”€â”€ evolution.py            # Evolves/improves responses  
â”‚   â”œâ”€â”€ proximity.py            # Checks proximity to past queries  
â”‚   â””â”€â”€ meta_review.py          # Evaluates performance  
â”‚
â”œâ”€â”€ supervisor/                 
â”‚   â””â”€â”€ supervisor.py           # Coordinates all agents  
â”‚
â”œâ”€â”€ storage/                    # Stores past queries, results, and cache  
â”‚   â””â”€â”€ memory.json             # Persistent memory storage  
â”‚
â”œâ”€â”€ main.py                     # Entry point for the app  
â”œâ”€â”€ requirements.txt            # Python dependencies  
â”œâ”€â”€ .env                        # API keys (e.g., OpenAI, Google)  
â””â”€â”€ README.md                   # Project info & setup instructions  
